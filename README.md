# ConnectsLab Speech

2023ë…„ 11ì›” 9ì¼ ~ 2023ë…„ 12ì›” 15ì¼ (37ì¼ê°„) ê¹Œì§€ ì´ì–´ë“œë¦¼ìŠ¤ì¿¨ì—ì„œ ì§„í–‰ëœ ê¸°ì—…ì—°ê³„ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

Speech-To-Text ë° Audio Gender Classification ê¸°ìˆ ì„ ì´ìš©í•©ë‹ˆë‹¤.

## ğŸ˜† Members

ê¸°ì—…í”„ë¡œì íŠ¸ì— ì°¸ê°€í•œ ë©¤ë²„ì…ë‹ˆë‹¤.

ğŸ˜† [ê¹€ë¯¼ì£¼](https://github.com/donaldducks) ğŸ˜† [ë°•ë¯¼ìˆ˜](https://github.com/pingu605) ğŸ˜† [ì´ì„ ë¯¼](https://github.com/GoX2Maker) ğŸ˜† [ì¡°ì¸ì² ](https://github.com/carryplz)
ğŸ˜† [ìµœí¬ì˜](https://github.com/MrSteveChoi)

## ğŸ“‚ Git íŒŒì¼ êµ¬ì¡°

```
.
â”œâ”€â”€ DeepSpeech2
â”‚Â Â  â”œâ”€â”€ configs
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ evalConfigs.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ trainConfigs.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ transcribeConfigs.yaml
â”‚Â Â  â”œâ”€â”€ deepspeech_pytorch
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ decoder.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ inference.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ loader
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data_loader.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ merge_manifests.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sparse_image_warp.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ spec_augment.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logger.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ model.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ state.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ testing.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ utils.py
â”‚Â Â  â”œâ”€â”€ eval.py
â”‚Â Â  â”œâ”€â”€ preprocessing
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 01_jsontocsv.ipynb
â”‚Â Â  â”‚Â Â  â””â”€â”€ 02_prepareDataset.ipynb
â”‚Â Â  â”œâ”€â”€ train.py
â”‚Â Â  â””â”€â”€ transcribe.py
|   â””â”€â”€ README.md
â”œâ”€â”€ classification
â”‚   â”œâ”€â”€ configs
â”‚   â”‚Â Â  â”œâ”€â”€ evalConfigs.yaml
â”‚   â”‚Â Â  â”œâ”€â”€ trainConfigs.yaml
â”‚   â”‚Â Â  â””â”€â”€ transcribeConfigs.yaml
â”‚   â”œâ”€â”€ eval.py
â”‚   â”œâ”€â”€ parts
â”‚   â”‚Â Â  â”œâ”€â”€ loader.py
â”‚   â”‚Â Â  â””â”€â”€ model.py
â”‚   â”œâ”€â”€ preprocessing
â”‚   â”‚Â Â  â”œâ”€â”€ 01_jsontocsv.ipynb
â”‚   â”‚Â Â  â””â”€â”€ 02_prepareDataset.ipynb
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ transcribe.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
â””â”€â”€ requirements.txt

10 directories, 31 files
```

## Wiki

í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ì„œ ì°¸ê³ í•œ ë…¼ë¬¸ ë° ìë£Œë¥¼ Wikiì— ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

ğŸ‘‰ğŸ» [ìœ„í‚¤ ë°”ë¡œê°€ê¸°](https://github.com/GoX2Maker/ConnectsLab_Speech/wiki)

# 1. ì»´í“¨í„° í™˜ê²½ ğŸ–¥ï¸

ì´ì–´ë“œë¦¼ ìŠ¤ì¿¨ì—ì„œ ì§€ì›ë°›ì€ ì„œë²„.

```
- GPU : T4 x 2
- RAM : 32GB
```

ì¶”ê°€ì ì¸ ê°œì¸ ìì›

```
- GPU : T4, 4090
- RAM : 64GB
```

# 2. ë°ì´í„°ì…‹(Data set)

## 2.1. ììœ ëŒ€í™” ìŒì„±

<img src="https://yt3.googleusercontent.com/ytc/APkrFKY22EDptTNlPABU91QU62THoc93tJ6DbGh2oVXI=s900-c-k-c0x00ffffff-no-rj" width="200"></img>

ğŸ‘‰ğŸ» [ììœ ëŒ€í™” ìŒì„± ë°”ë¡œê°€ê¸°](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=109)

AI-Hubì˜ "í•œêµ­ì–´ ììœ ëŒ€í™” ìŒì„±" ë°ì´í„°ë¡œ í•™ìŠµì„ í–ˆìŠµë‹ˆë‹¤. ì§€ì›ë°›ì€ ì»´í“¨í„° ìì›ì„ ê³ ë ¤í•´ì„œ ë°ì´í„°ë¥¼ ì„ ë³„í–ˆìŠµë‹ˆë‹¤.
í•´ë‹¹ ë°ì´í„°ë¡œ STT ë° Classfication ë°ì´í„° ì…‹ìœ¼ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤.

ì„ ë³„ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

- ë‚¨ë…€ : 5:5
- ë‚˜ì´ëŒ€ : ì•„ì´ë¥¼ í‚¤ìš¸ í™•ë¥ ì´ ë†’ë‹¤ê³  íŒë‹¨ë˜ëŠ” 20ì‚´ ~ 40ì‚´ë¡œ ì„¤ì •
- ìŒì„± í›ˆë ¨ë°ì´í„° ì‹œê°„ : 200ì‹œê°„, 1,000ì‹œê°„ (ì»´í“¨íŒ… ìì› ê³ ë ¤)
- ìŒì„± í‰ê°€ë°ì´í„° ì‹œê°„ : 20ì‹œê°„

## 2.2. ì†ŒìŒë°ì´í„°

<img src="https://yt3.googleusercontent.com/ytc/APkrFKY22EDptTNlPABU91QU62THoc93tJ6DbGh2oVXI=s900-c-k-c0x00ffffff-no-rj" width="200"></img>

ğŸ‘‰ğŸ» [ì†ŒìŒë°ì´í„° ë°”ë¡œê°€ê¸°](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71405)

ì†ŒìŒì´ ìˆëŠ” í™˜ê²½ì—ì„œì˜ STT ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ì†ŒìŒë°ì´í„°ë¥¼ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

- ë…¹ìŒ í™˜ê²½ : ê°€ì •ì—ì„œì˜ ì†ŒìŒí™˜ê²½ (ì²­ì†Œê¸° ì†ŒìŒ, ì„¸íƒê¸° ì†ŒìŒ ë“±)
- ìŒì„± ë°ì´í„° ì‹œê°„ : 50ì‹œê°„

# 3. STT(Speech-To-Text)

STTë¡œ Deepspeech2ì™€ Whisperë¥¼ ì´ìš©í–ˆìŠµë‹ˆë‹¤.

ì²˜ìŒ ë‹¤ë¤„ë³´ëŠ” STT modelì´ê¸° ë•Œë¬¸ì— E2E-ASRì˜ ê¸°ì´ˆ ê°œë…ë¶€í„° ë‹¤ë¤„ë³¼ ìˆ˜ ìˆëŠ” ëª¨ë¸ì¸ Deepspeech2ë¥¼ ì„ ì •í•˜ì˜€ìŠµë‹ˆë‹¤.

ì´í›„ edge deviceì—ì„œë„ í™œìš© ê°€ëŠ¥í•œ ê°€ë²¼ìš´ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì¸ Whisper-tinyë¥¼ íŒŒì¸íŠœë‹ í›„ í•œêµ­ì–´ ììœ ëŒ€í™” ìŒì„± ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ scratch trainingëœ DeepSpeech2 ëª¨ë¸ê³¼ì˜ ì„±ëŠ¥ë¹„êµë¥¼ í–ˆìŠµë‹ˆë‹¤.

## 3.1. Whisper

### 3.1.1. Whisper Fine-turing

ì˜¤í”ˆ ì†ŒìŠ¤ì´ë©°, ë‹¤ì–‘í•œ ì–¸ì–´ì— ëŒ€í•´ì„œ ì œë¡œìƒ· ì„±ëŠ¥ì´ ì¢‹ê³  ìµœê·¼ì— ì˜ìƒ ìë™ìë§‰ taskì—ì„œ ë„ë¦¬ ì“°ì´ëŠ” ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— Whisperë¥¼ ê¸°ì¤€ ëª¨ë¸ë¡œ ì„ ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
ë˜í•œ edge-deviceì—ì„œì˜ í™œìš©ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ê°€ë²¼ìš´ ëª¨ë¸ì¸ Whisper-tinyë¥¼ ë¹„êµêµ°ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.

|     êµ¬ë¶„      |           íŒŒë¼ë¯¸í„°           | ë…¸ì´ì¦ˆ ì œê±°ìœ ë¬´ | ì¼ë°˜ ìŒì„± CER | ì›ê±°ë¦¬ ì†ŒìŒ CER | ê·¼ê±°ë¦¬ ì†ŒìŒ CER |                 ë¹„ê³                  |
| :-----------: | :--------------------------: | :-------------: | :-----------: | :-------------: | :-------------: | :----------------------------------: |
| whisper-tiny  |              X               |        X        |    29.71%     |     72.73%      |     76.03%      |              ì¼ë°˜ ëª¨ë¸               |
| fine-tuning 1 | max_steps 1000 batch_size 32 |        X        |    32.90%     |     91.45%      |     85.62%      |              í•™ìŠµ ì‹¤í—˜               |
| fine-tuning 2 | max_stpes 4500 batch_size 32 |        X        |    19.53%     |     123.78%     |     109.89%     |                1epoch                |
| fine-tuning 3 | max_stpes 4500 batch_size 64 |        X        |    31.40%     |     118.56%     |     112.37%     |                2epoch                |
| fine-tuning 4 | max_stpes 4500 batch_size 32 |        O        |       X       |     189.64%     |     153.44%     | 1epoch ëª¨ë¸ + noisereduce ë¼ì´ë¸ŒëŸ¬ë¦¬ |

## 3.2. DeepSpeech2

ê¸°ì¡´ì˜ DeepSpeech2ê°€ ì‚¬ìš©í•˜ë˜ CTCLoss libraryê°€ ì§€ì› ì¢…ë£Œë˜ì–´ ì´ë¥¼ pytorch.nn.CTCLossë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.<br>
í•œêµ­ì–´ STTí•˜ë©´ì„œ ì—¬ëŸ¬ ì—ëŸ¬ ë°œìƒí–ˆëŠ”ë° ì´ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.

### 3.2.1. í•œêµ­ì–´ DeepSpeech2 ì‚¬ìš©ë°©ë²•

DeepSpeech2 ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ [README.md](https://github.com/GoX2Maker/ConnectsLab_Speech/blob/main/DeepSpeech2/README.md)ì— ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

### 3.2.2. Train ê²°ê³¼

ì»´í“¨í„° ìì›ì— ë”°ë¼ í•™ìŠµë°ì´í„°ë¥¼ ë‹¤ë¥´ê²Œ í–ˆìŠµë‹ˆë‹¤.<br>
(200ì‹œê°„ ë°ì´í„°ë¥¼ T4ë¡œ ëŒë ¸ì„ ë•Œ 1epochì— 3ì‹œê°„ ì •ë„ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤.)

|       êµ¬ë¶„       | ë…¸ì´ì¦ˆ ì œê±°ìœ ë¬´ | ì¼ë°˜ ìŒì„± CER | ì›ê±°ë¦¬ ì†ŒìŒ CER | ê·¼ê±°ë¦¬ ì†ŒìŒ CER |         ë¹„ê³           |
| :--------------: | :-------------: | :-----------: | :-------------: | :-------------: | :-------------------: |
|  200ì‹œê°„ ë°ì´í„°  |        X        |      16%      |       62%       |       53%       | 5 epoch (best model)  |
| 1,000ì‹œê°„ ë°ì´í„° |        X        |      10%      |       56%       |       47%       | 11 epoch (best model) |

### 3.2.3. DeepSpeech2 VS Whisper-tiny

scratch trainingëœ DeepSpeech2 ëª¨ë¸ì´ Whisper-tiny íŒŒì¸íŠœë‹ë³´ë‹¤ ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

|          êµ¬ë¶„           | ë…¸ì´ì¦ˆ ì œê±°ìœ ë¬´ | ì¼ë°˜ ìŒì„± CER | ì›ê±°ë¦¬ ì†ŒìŒ CER | ê·¼ê±°ë¦¬ ì†ŒìŒ CER |
| :---------------------: | :-------------: | :-----------: | :-------------: | :-------------: |
|    DEEP Speech2 Best    |        X        |    10.23%     |     56.59%      |     47.11%      |
| whisper-finetuning Best |        X        |    19.53%     |     123.78%     |     109.89%     |
|      whisper-tiny       |        X        |    29.71%     |     72.73%      |     76.03%      |

### 3.2.4. DeepSpeech2 í—ˆê¹…í˜ì´ìŠ¤

<img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="200" title="gender classification model"></img>

ì•„ë˜ì˜ í—ˆê¹…í˜ì´ìŠ¤ ë§í¬ë¥¼ í†µí•´ DeepSpeech2 ëª¨ë¸ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ‘‰ğŸ» [í—ˆê¹…í˜ì´ìŠ¤ ë°”ë¡œê°€ê¸°](https://huggingface.co/spaces/GOx2Maker/DeepSpeech2_Kor)

## 3.3. ì°¸ê³ ìë£Œ

- [Awesome-Korean-Speech-Recognition](https://github.com/rtzr/Awesome-Korean-Speech-Recognition)
  - í•œêµ­ì–´ ìŒì„±ë°ì´í„°ë¡œ í•™ìŠµëœ STT APIë“¤ê°„ì˜ ì„±ëŠ¥ë¹„êµí‘œ ì°¸ê³ .
- [DeepSpeech2 Kor](https://github.com/fd873630/deep_speech_2_korean)
  - DeepSpeech2 í•œêµ­ì–´ ì½”ë“œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.
- [DeepSpeech2](https://github.com/SeanNaren/deepspeech.pytorch)
  - DeepSpeech2 ì½”ë“œ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.
- [Whisper-fine-tuning](https://colab.research.google.com/github/huggingface/community-events/blob/main/whisper-fine-tuning-event/fine_tune_whisper_streaming_colab.ipynb)
  - Whisper fine tuningì„ í•  ë•Œ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.
- [Whisper í•œêµ­ì–´ íŒŒì¸ë“€ë‹ ë…¼ë¬¸](https://www.eksss.org/archive/view_article?pid=pss-15-3-75)
  - Whisper í•œêµ­ì–´ íŒŒì¸ë“€ë‹ ë…¼ë¬¸ìë£Œì…ë‹ˆë‹¤.

# 4. Classification

ë¶€ëª¨ê°„ì˜ ë°œí™”ë¹„ìœ¨ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ìŒì„±ë°ì´í„° ìƒíƒœì—ì„œ ë°œí™”ìì˜ ì„±ë³„ì„ ë¶„ë¥˜í•˜ëŠ” Gender Classification modelì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.

## 4.1. ëª¨ë¸êµ¬ì¡°

ì œì‘í•œ ëª¨ë¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

<img src="image.png" width="500px" height="300px" title="gender classification model"></img>

## 4.2. ìŒì„± ë¶„ë¥˜ ì‚¬ìš©ë°©ë²•

ìŒì„± ë¶„ë¥˜ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ [README.md](https://github.com/GoX2Maker/ConnectsLab_Speech/blob/main/classification/README.md)ì— ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

## 4.3. ìŒì„± ë¶„ë¥˜ í—ˆê¹…í˜ì´ìŠ¤

<img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="200" title="gender classification model"></img>

ì„±ë³„ ë¶„ë¥˜ ê²°ê³¼ Test Setì—ì„œ 0.98(acc)ë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
í•´ë‹¹ ëª¨ë¸ì€ ì•„ë˜ì˜ í—ˆê¹…í˜ì´ìŠ¤ ë§í¬ë¥¼ í†µí•´ í™•ì¸í•´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ‘‰ğŸ» [í—ˆê¹…í˜ì´ìŠ¤ ë°”ë¡œê°€ê¸°](https://huggingface.co/spaces/GOx2Maker/audio_gender_classifier)
